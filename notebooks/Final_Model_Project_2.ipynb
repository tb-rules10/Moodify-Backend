{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fH5svYRbdtOl",
        "outputId": "a1205fa0-0f02-439c-a40a-223caa34b7a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1kVDtJJeexqi"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import data_table\n",
        "import re\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from textblob import TextBlob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "id": "b5Smg83BezRn",
        "outputId": "eaea34fa-1938-4a27-db5f-dc3df32c8a11"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Emotion</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neutral</td>\n",
              "      <td>Why ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>joy</td>\n",
              "      <td>Sage Act upgrade on my to do list for tommorow.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sadness</td>\n",
              "      <td>ON THE WAY TO MY HOMEGIRL BABY FUNERAL!!! MAN ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>joy</td>\n",
              "      <td>Such an eye ! The true hazel eye-and so brill...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>joy</td>\n",
              "      <td>@Iluvmiasantos ugh babe.. hugggzzz for u .!  b...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "application/vnd.google.colaboratory.module+javascript": "\n      import \"https://ssl.gstatic.com/colaboratory/data_table/99dac6621f6ae8c4/data_table.js\";\n\n      window.createDataTable({\n        data: [[{\n            'v': 0,\n            'f': \"0\",\n        },\n\"neutral\",\n\" Why ? \"],\n [{\n            'v': 1,\n            'f': \"1\",\n        },\n\"joy\",\n\"Sage Act upgrade on my to do list for tommorow.\"],\n [{\n            'v': 2,\n            'f': \"2\",\n        },\n\"sadness\",\n\"ON THE WAY TO MY HOMEGIRL BABY FUNERAL!!! MAN I HATE FUNERALS THIS REALLY SHOWS ME HOW BLESSED I AM \"],\n [{\n            'v': 3,\n            'f': \"3\",\n        },\n\"joy\",\n\" Such an eye ! The true hazel eye-and so brilliant ! Regular features , open countenance , with a complexion , Oh ! What a bloom of full health , and such a pretty height and size ; such a firm and upright figure ! There is health , not merely in her bloom , but in her air , her head , her glance . One hears sometimes of a child being ' the picture of health ' ; now , she always gives me the idea of being the complete picture of grown-up health . She is loveliness itself . \"],\n [{\n            'v': 4,\n            'f': \"4\",\n        },\n\"joy\",\n\"@Iluvmiasantos ugh babe.. hugggzzz for u .!  babe naamazed nga ako e babe e, despite nega's mas pinaramdam at fil ko ang \"]],\n        columns: [[\"number\", \"index\"], [\"string\", \"Emotion\"], [\"string\", \"Text\"]],\n        columnOptions: [{\"width\": \"1px\", \"className\": \"index_column\"}],\n        rowsPerPage: 25,\n        helpUrl: \"https://colab.research.google.com/notebooks/data_table.ipynb\",\n        suppressOutputScrolling: true,\n        minimumWidth: undefined,\n      });\n    ",
            "text/plain": [
              "<google.colab.data_table.DataTable object>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/ML datasets/emotion-dataset(updated-final).csv\")\n",
        "data_table.DataTable(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTO8PlpfXn_W",
        "outputId": "54d786ef-5631-4a8d-8fd1-2a1b51751d9b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sadness     16553\n",
              "joy         16407\n",
              "fear         7347\n",
              "anger        6566\n",
              "love         5146\n",
              "surprise     4634\n",
              "neutral      2254\n",
              "disgust       856\n",
              "shame         146\n",
              "Name: Emotion, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "df['Emotion'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ID52RnlOXaEI"
      },
      "outputs": [],
      "source": [
        "df = df[df.Emotion != 'disgust']\n",
        "df = df[df.Emotion != 'surprise']\n",
        "df = df[df.Emotion != 'shame']\n",
        "# df = df[df.Emotion != 'fear']\n",
        "# df = df[df.Emotion != 'anger']\n",
        "# df = df[df.Emotion != 'love']\n",
        "# df = df[df.Emotion != 'neutral']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63VaI_fEe75G",
        "outputId": "fbd92473-a40d-4c55-9a5e-20c07e2c96b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: neattext in /usr/local/lib/python3.10/dist-packages (0.1.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install neattext\n",
        "import neattext.functions as nfx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "hOOIphowfLMr",
        "outputId": "de5d688b-420f-405c-e857-6953d4e29374"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Clean_Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Why ?</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sage Act upgrade on my to do list for tommorow.</td>\n",
              "      <td>sage act upgrade list tommorow</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ON THE WAY TO MY HOMEGIRL BABY FUNERAL!!! MAN ...</td>\n",
              "      <td>way homegirl baby funeral man hate funeral rea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Such an eye ! The true hazel eye-and so brill...</td>\n",
              "      <td>eye true hazel eye brilliant regular feature o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@Iluvmiasantos ugh babe.. hugggzzz for u .!  b...</td>\n",
              "      <td>iluvmiasantos ugh babe hugggzzz u babe naamaze...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "application/vnd.google.colaboratory.module+javascript": "\n      import \"https://ssl.gstatic.com/colaboratory/data_table/99dac6621f6ae8c4/data_table.js\";\n\n      window.createDataTable({\n        data: [[{\n            'v': 0,\n            'f': \"0\",\n        },\n\" Why ? \",\n\"\"],\n [{\n            'v': 1,\n            'f': \"1\",\n        },\n\"Sage Act upgrade on my to do list for tommorow.\",\n\"sage act upgrade list tommorow\"],\n [{\n            'v': 2,\n            'f': \"2\",\n        },\n\"ON THE WAY TO MY HOMEGIRL BABY FUNERAL!!! MAN I HATE FUNERALS THIS REALLY SHOWS ME HOW BLESSED I AM \",\n\"way homegirl baby funeral man hate funeral really show blessed\"],\n [{\n            'v': 3,\n            'f': \"3\",\n        },\n\" Such an eye ! The true hazel eye-and so brilliant ! Regular features , open countenance , with a complexion , Oh ! What a bloom of full health , and such a pretty height and size ; such a firm and upright figure ! There is health , not merely in her bloom , but in her air , her head , her glance . One hears sometimes of a child being ' the picture of health ' ; now , she always gives me the idea of being the complete picture of grown-up health . She is loveliness itself . \",\n\"eye true hazel eye brilliant regular feature open countenance complexion oh bloom full health pretty height size firm upright figure health merely bloom air head glance one hears sometimes child picture health always give idea complete picture grown health loveliness\"],\n [{\n            'v': 4,\n            'f': \"4\",\n        },\n\"@Iluvmiasantos ugh babe.. hugggzzz for u .!  babe naamazed nga ako e babe e, despite nega's mas pinaramdam at fil ko ang \",\n\"iluvmiasantos ugh babe hugggzzz u babe naamazed nga ako e babe e despite nega ma pinaramdam fil ko ang\"]],\n        columns: [[\"number\", \"index\"], [\"string\", \"Text\"], [\"string\", \"Clean_Text\"]],\n        columnOptions: [{\"width\": \"1px\", \"className\": \"index_column\"}],\n        rowsPerPage: 25,\n        helpUrl: \"https://colab.research.google.com/notebooks/data_table.ipynb\",\n        suppressOutputScrolling: true,\n        minimumWidth: undefined,\n      });\n    ",
            "text/plain": [
              "<google.colab.data_table.DataTable object>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"wordnet\")\n",
        "\n",
        "def clean_sentence(sentence):\n",
        "    # Remove special characters and numbers\n",
        "    sentence = re.sub(r'[^a-zA-Z]', ' ', sentence)\n",
        "    # Convert to lowercase\n",
        "    sentence = sentence.lower()\n",
        "    # Remove URLs\n",
        "    sentence = re.sub(r'http\\S+', '', sentence)\n",
        "    # Split into words\n",
        "    sentence = sentence.split()\n",
        "    # Remove stopwords\n",
        "    sentence = [word for word in sentence if not word in set(stopwords.words('english'))]\n",
        "    # Perform lemmatization\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    sentence = [lemmatizer.lemmatize(word) for word in sentence]\n",
        "    # Join the words back together\n",
        "    sentence = ' '.join(sentence)\n",
        "    return sentence\n",
        "\n",
        "\n",
        "df['Clean_Text'] = df['Text'].apply(nfx.remove_punctuations)\n",
        "df['Clean_Text'] = df['Clean_Text'].apply(nfx.remove_stopwords)\n",
        "df['Clean_Text'] = df['Clean_Text'].apply(nfx.remove_userhandles)\n",
        "df['Clean_Text'] = df['Text'].apply(lambda x: clean_sentence(x))\n",
        "\n",
        "\n",
        "data_table.DataTable(df[['Text','Clean_Text']].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKBr_DYb49-n",
        "outputId": "4e64036e-c558-4daa-9cde-be5e6a29a3f1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Emotion       0\n",
              "Text          0\n",
              "Clean_Text    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXUptkBaUxRU",
        "outputId": "777348fe-d582-4f97-edb1-7cf6c47fa5fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy (Naive Bayes): 63.29%\n",
            "Testing Accuracy (Naive Bayes): 63.33%\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load data\n",
        "data = df\n",
        "\n",
        "# Split data into training, validation, and testing sets\n",
        "train_data, test_data, train_labels, test_labels = train_test_split(data['Clean_Text'], data['Emotion'], test_size=0.2, random_state=42)\n",
        "train_data, val_data, train_labels, val_labels = train_test_split(train_data, train_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Vectorize text data using CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "train_features = vectorizer.fit_transform(train_data)\n",
        "val_features = vectorizer.transform(val_data)\n",
        "test_features = vectorizer.transform(test_data)\n",
        "\n",
        "# Train a Naive Bayes model\n",
        "nb = MultinomialNB()\n",
        "nb.fit(train_features, train_labels)\n",
        "\n",
        "# Make predictions on the validation and test sets\n",
        "val_predictions = nb.predict(val_features)\n",
        "test_predictions = nb.predict(test_features)\n",
        "\n",
        "# Evaluate model performance on validation and test sets\n",
        "val_accuracy = accuracy_score(val_labels, val_predictions)\n",
        "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
        "\n",
        "print(\"Validation Accuracy (Naive Bayes): {:.2f}%\".format(val_accuracy * 100))\n",
        "print(\"Testing Accuracy (Naive Bayes): {:.2f}%\".format(test_accuracy * 100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cl577jqXVF2x",
        "outputId": "d0709df6-0926-448c-db63-ef0e021be13c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report (Validation Set):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.80      0.43      0.56      1096\n",
            "        fear       0.79      0.54      0.64      1174\n",
            "         joy       0.62      0.80      0.70      2645\n",
            "        love       0.76      0.31      0.44       831\n",
            "     neutral       0.60      0.01      0.02       351\n",
            "     sadness       0.57      0.77      0.66      2587\n",
            "\n",
            "    accuracy                           0.63      8684\n",
            "   macro avg       0.69      0.48      0.50      8684\n",
            "weighted avg       0.66      0.63      0.61      8684\n",
            "\n",
            "Classification Report (Test Set):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.77      0.43      0.55      1264\n",
            "        fear       0.77      0.53      0.63      1475\n",
            "         joy       0.62      0.80      0.70      3301\n",
            "        love       0.79      0.31      0.44      1043\n",
            "     neutral       0.50      0.01      0.01       455\n",
            "     sadness       0.58      0.77      0.66      3317\n",
            "\n",
            "    accuracy                           0.63     10855\n",
            "   macro avg       0.67      0.48      0.50     10855\n",
            "weighted avg       0.66      0.63      0.61     10855\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Generate classification report for validation set\n",
        "val_report = classification_report(val_labels, val_predictions)\n",
        "print(\"Classification Report (Validation Set):\\n\", val_report)\n",
        "\n",
        "# Generate classification report for test set\n",
        "test_report = classification_report(test_labels, test_predictions)\n",
        "print(\"Classification Report (Test Set):\\n\", test_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UP2gHGtSdYc",
        "outputId": "7e0a9c1b-0c5d-4dd2-990d-2bd615a4868c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 70.65%\n",
            "Testing Accuracy: 70.50%\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load data\n",
        "data = df\n",
        "\n",
        "# Split data into training, validation, and testing sets\n",
        "train_data, test_data, train_labels, test_labels = train_test_split(data['Clean_Text'], data['Emotion'], test_size=0.2, random_state=42)\n",
        "train_data, val_data, train_labels, val_labels = train_test_split(train_data, train_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Vectorize text data using CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "train_features = vectorizer.fit_transform(train_data)\n",
        "val_features = vectorizer.transform(val_data)\n",
        "test_features = vectorizer.transform(test_data)\n",
        "\n",
        "# Train a Logistic Regression model\n",
        "lr = LogisticRegression(max_iter=1000)\n",
        "lr.fit(train_features, train_labels)\n",
        "\n",
        "# Make predictions on the validation and test sets\n",
        "val_predictions = lr.predict(val_features)\n",
        "test_predictions = lr.predict(test_features)\n",
        "\n",
        "# Evaluate model performance on validation and test sets\n",
        "val_accuracy = accuracy_score(val_labels, val_predictions)\n",
        "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
        "\n",
        "print(\"Validation Accuracy: {:.2f}%\".format(val_accuracy * 100))\n",
        "print(\"Testing Accuracy: {:.2f}%\".format(test_accuracy * 100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxzgRHpDVNLs",
        "outputId": "1e65b28e-0e0c-4a54-b14c-ebef08305358"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report (Validation Set):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.77      0.60      0.67      1096\n",
            "        fear       0.79      0.69      0.74      1174\n",
            "         joy       0.71      0.77      0.74      2645\n",
            "        love       0.67      0.54      0.60       831\n",
            "     neutral       0.54      0.71      0.61       351\n",
            "     sadness       0.69      0.75      0.72      2587\n",
            "\n",
            "    accuracy                           0.71      8684\n",
            "   macro avg       0.70      0.68      0.68      8684\n",
            "weighted avg       0.71      0.71      0.71      8684\n",
            "\n",
            "Classification Report (Test Set):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.73      0.61      0.67      1264\n",
            "        fear       0.77      0.70      0.73      1475\n",
            "         joy       0.70      0.78      0.74      3301\n",
            "        love       0.68      0.51      0.58      1043\n",
            "     neutral       0.58      0.72      0.64       455\n",
            "     sadness       0.70      0.73      0.72      3317\n",
            "\n",
            "    accuracy                           0.71     10855\n",
            "   macro avg       0.69      0.67      0.68     10855\n",
            "weighted avg       0.71      0.71      0.70     10855\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Generate classification report for validation set\n",
        "val_report = classification_report(val_labels, val_predictions)\n",
        "print(\"Classification Report (Validation Set):\\n\", val_report)\n",
        "\n",
        "# Generate classification report for test set\n",
        "test_report = classification_report(test_labels, test_predictions)\n",
        "print(\"Classification Report (Test Set):\\n\", test_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QgXY11Kwt_m1",
        "outputId": "f11101e1-ffe1-43d3-902f-80dd7da849ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy (L1 regularization): 70.83%\n",
            "Testing Accuracy (L1 regularization): 71.12%\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load data\n",
        "data = df\n",
        "\n",
        "# Split data into training, validation, and testing sets\n",
        "train_data, test_data, train_labels, test_labels = train_test_split(data['Clean_Text'], data['Emotion'], test_size=0.2, random_state=42)\n",
        "train_data, val_data, train_labels, val_labels = train_test_split(train_data, train_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Vectorize text data using CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "train_features = vectorizer.fit_transform(train_data)\n",
        "val_features = vectorizer.transform(val_data)\n",
        "test_features = vectorizer.transform(test_data)\n",
        "\n",
        "# Train a Logistic Regression model with L1 regularization\n",
        "lr_l1 = LogisticRegression(max_iter=1000, penalty='l1', solver='liblinear')\n",
        "lr_l1.fit(train_features, train_labels)\n",
        "\n",
        "# Make predictions on the validation and test sets\n",
        "val_predictions = lr_l1.predict(val_features)\n",
        "test_predictions = lr_l1.predict(test_features)\n",
        "\n",
        "# Evaluate model performance on validation and test sets\n",
        "val_accuracy = accuracy_score(val_labels, val_predictions)\n",
        "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
        "\n",
        "print(\"Validation Accuracy (L1 regularization): {:.2f}%\".format(val_accuracy * 100))\n",
        "print(\"Testing Accuracy (L1 regularization): {:.2f}%\".format(test_accuracy * 100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qts9iPk7VPJt",
        "outputId": "cc0bd066-a66f-4d75-af9b-d37b412c1314"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report (Validation Set):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.80      0.59      0.68      1096\n",
            "        fear       0.81      0.67      0.74      1174\n",
            "         joy       0.70      0.78      0.74      2645\n",
            "        love       0.67      0.56      0.61       831\n",
            "     neutral       0.59      0.60      0.59       351\n",
            "     sadness       0.68      0.76      0.72      2587\n",
            "\n",
            "    accuracy                           0.71      8684\n",
            "   macro avg       0.71      0.66      0.68      8684\n",
            "weighted avg       0.71      0.71      0.71      8684\n",
            "\n",
            "Classification Report (Test Set):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.77      0.59      0.67      1264\n",
            "        fear       0.79      0.69      0.74      1475\n",
            "         joy       0.70      0.79      0.74      3301\n",
            "        love       0.68      0.53      0.60      1043\n",
            "     neutral       0.63      0.63      0.63       455\n",
            "     sadness       0.70      0.75      0.72      3317\n",
            "\n",
            "    accuracy                           0.71     10855\n",
            "   macro avg       0.71      0.67      0.68     10855\n",
            "weighted avg       0.71      0.71      0.71     10855\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Generate classification report for validation set\n",
        "val_report = classification_report(val_labels, val_predictions)\n",
        "print(\"Classification Report (Validation Set):\\n\", val_report)\n",
        "\n",
        "# Generate classification report for test set\n",
        "test_report = classification_report(test_labels, test_predictions)\n",
        "print(\"Classification Report (Test Set):\\n\", test_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-KCYgdssB5T",
        "outputId": "154a08fe-e0e5-46a5-c1ed-e25d7cdb8cdf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 68.24%\n",
            "Testing Accuracy: 68.45%\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load data\n",
        "data = df\n",
        "\n",
        "# Split data into training, validation, and testing sets\n",
        "train_data, test_data, train_labels, test_labels = train_test_split(data['Clean_Text'], data['Emotion'], test_size=0.2, random_state=42)\n",
        "train_data, val_data, train_labels, val_labels = train_test_split(train_data, train_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Vectorize text data using CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "train_features = vectorizer.fit_transform(train_data)\n",
        "val_features = vectorizer.transform(val_data)\n",
        "test_features = vectorizer.transform(test_data)\n",
        "\n",
        "# Train a SVM model\n",
        "svm = SVC(kernel='rbf')\n",
        "svm.fit(train_features, train_labels)\n",
        "\n",
        "# Make predictions on the validation and test sets\n",
        "val_predictions = svm.predict(val_features)\n",
        "test_predictions = svm.predict(test_features)\n",
        "\n",
        "# Evaluate model performance on validation and test sets\n",
        "val_accuracy = accuracy_score(val_labels, val_predictions)\n",
        "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
        "\n",
        "print(\"Validation Accuracy: {:.2f}%\".format(val_accuracy * 100))\n",
        "print(\"Testing Accuracy: {:.2f}%\".format(test_accuracy * 100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1qZNuBS-VZcQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8e3cd5c-57e3-4b29-ac79-00e2e1dfd2ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report (Validation Set):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.89      0.46      0.61      1096\n",
            "        fear       0.88      0.57      0.69      1174\n",
            "         joy       0.65      0.81      0.72      2645\n",
            "        love       0.73      0.42      0.53       831\n",
            "     neutral       0.61      0.72      0.66       351\n",
            "     sadness       0.63      0.78      0.69      2587\n",
            "\n",
            "    accuracy                           0.68      8684\n",
            "   macro avg       0.73      0.63      0.65      8684\n",
            "weighted avg       0.71      0.68      0.68      8684\n",
            "\n",
            "Classification Report (Test Set):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.85      0.45      0.59      1264\n",
            "        fear       0.88      0.61      0.72      1475\n",
            "         joy       0.65      0.81      0.73      3301\n",
            "        love       0.72      0.41      0.52      1043\n",
            "     neutral       0.64      0.71      0.67       455\n",
            "     sadness       0.64      0.76      0.70      3317\n",
            "\n",
            "    accuracy                           0.68     10855\n",
            "   macro avg       0.73      0.63      0.65     10855\n",
            "weighted avg       0.71      0.68      0.68     10855\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Generate classification report for validation set\n",
        "val_report = classification_report(val_labels, val_predictions)\n",
        "print(\"Classification Report (Validation Set):\\n\", val_report)\n",
        "\n",
        "# Generate classification report for test set\n",
        "test_report = classification_report(test_labels, test_predictions)\n",
        "print(\"Classification Report (Test Set):\\n\", test_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D4ve8ckVttkl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf0b8c62-1a47-4cdb-f2a1-9ff26f7ee0ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy (Random Forest): 67.07%\n",
            "Testing Accuracy (Random Forest): 67.38%\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load data\n",
        "data = df\n",
        "\n",
        "# Split data into training, validation, and testing sets\n",
        "train_data, test_data, train_labels, test_labels = train_test_split(data['Clean_Text'], data['Emotion'], test_size=0.2, random_state=42)\n",
        "train_data, val_data, train_labels, val_labels = train_test_split(train_data, train_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Vectorize text data using CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "train_features = vectorizer.fit_transform(train_data)\n",
        "val_features = vectorizer.transform(val_data)\n",
        "test_features = vectorizer.transform(test_data)\n",
        "\n",
        "# Train a simple Random Forest model\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(train_features, train_labels)\n",
        "\n",
        "# Make predictions on the validation and test sets\n",
        "val_predictions = rf.predict(val_features)\n",
        "test_predictions = rf.predict(test_features)\n",
        "\n",
        "# Evaluate model performance on validation and test sets\n",
        "val_accuracy = accuracy_score(val_labels, val_predictions)\n",
        "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
        "\n",
        "print(\"Validation Accuracy (Random Forest): {:.2f}%\".format(val_accuracy * 100))\n",
        "print(\"Testing Accuracy (Random Forest): {:.2f}%\".format(test_accuracy * 100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ADEbfdAKVYAo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "654c141f-c3a4-4c68-d40c-cdf72cbacdb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report (Validation Set):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.81      0.57      0.67      1096\n",
            "        fear       0.87      0.63      0.73      1174\n",
            "         joy       0.69      0.75      0.72      2645\n",
            "        love       0.70      0.48      0.57       831\n",
            "     neutral       0.29      0.81      0.42       351\n",
            "     sadness       0.69      0.69      0.69      2587\n",
            "\n",
            "    accuracy                           0.67      8684\n",
            "   macro avg       0.67      0.65      0.63      8684\n",
            "weighted avg       0.71      0.67      0.68      8684\n",
            "\n",
            "Classification Report (Test Set):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.73      0.55      0.63      1264\n",
            "        fear       0.87      0.67      0.76      1475\n",
            "         joy       0.69      0.76      0.72      3301\n",
            "        love       0.71      0.45      0.55      1043\n",
            "     neutral       0.28      0.79      0.42       455\n",
            "     sadness       0.72      0.69      0.70      3317\n",
            "\n",
            "    accuracy                           0.67     10855\n",
            "   macro avg       0.67      0.65      0.63     10855\n",
            "weighted avg       0.71      0.67      0.68     10855\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Generate classification report for validation set\n",
        "val_report = classification_report(val_labels, val_predictions)\n",
        "print(\"Classification Report (Validation Set):\\n\", val_report)\n",
        "\n",
        "# Generate classification report for test set\n",
        "test_report = classification_report(test_labels, test_predictions)\n",
        "print(\"Classification Report (Test Set):\\n\", test_report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9GUwJbjjZ8Qq"
      },
      "outputs": [],
      "source": [
        "def rec(input):\n",
        "  input = vectorizer.transform([input])\n",
        "  input = input.toarray()\n",
        "  input = input.flatten()\n",
        "  pre = lr.predict([input])\n",
        "  print(f'Result:',pre[0])\n",
        "  recommeded_songs = get_songs_by_emotion(pre[0])\n",
        "  print(f'Songs:',recommeded_songs)\n",
        "  return recommeded_songs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ybtWM8EQe5sE"
      },
      "outputs": [],
      "source": [
        "# import random\n",
        "\n",
        "# data = pd.read_csv(\"/content/drive/MyDrive/ML datasets/Cleaned_Bollywood_dataset.csv\")\n",
        "\n",
        "# def get_songs_by_emotion(emotion):\n",
        "#     song_list = []\n",
        "#     for i in data.index:\n",
        "#         if data.loc[i, \"emotion\"] == emotion:\n",
        "#             song_list.append(data.loc[i, \"Song-Name\"])\n",
        "#     return random.sample(song_list,3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pA_2iOdD37fE"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import random\n",
        "\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/ML datasets/Cleaned_Bollywood_dataset.csv\")\n",
        "\n",
        "def get_songs_by_emotion(emotion):\n",
        "    song_list = []\n",
        "    for i in data.index:\n",
        "        if data.loc[i, \"emotion\"] == emotion:\n",
        "            song_list.append({\n",
        "                \"videoId\": data.loc[i, \"Song-Name\"],\n",
        "                \"title\": data.loc[i, \"Song-Name\"],\n",
        "                \"thumbnailUrl\": data.loc[i, \"Song-Name\"],\n",
        "                \"channelTitle\": data.loc[i, \"Song-Name\"]\n",
        "            })\n",
        "    return json.dumps(random.sample(song_list,3))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "afvcxOvraMqm",
        "outputId": "9c8895ec-7ba4-4683-a16e-e44d7dfc33e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Result: sadness\n",
            "Songs: [{\"videoId\": \"Tujhse Naaraz Nahi Zindagi\", \"title\": \"Tujhse Naaraz Nahi Zindagi\", \"thumbnailUrl\": \"Tujhse Naaraz Nahi Zindagi\", \"channelTitle\": \"Tujhse Naaraz Nahi Zindagi\"}, {\"videoId\": \"Jay-Jaykara\", \"title\": \"Jay-Jaykara\", \"thumbnailUrl\": \"Jay-Jaykara\", \"channelTitle\": \"Jay-Jaykara\"}, {\"videoId\": \"Yeh Kasoor Mera Hai\", \"title\": \"Yeh Kasoor Mera Hai\", \"thumbnailUrl\": \"Yeh Kasoor Mera Hai\", \"channelTitle\": \"Yeh Kasoor Mera Hai\"}]\n",
            "Statement: My life is messed up\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'[{\"videoId\": \"Tujhse Naaraz Nahi Zindagi\", \"title\": \"Tujhse Naaraz Nahi Zindagi\", \"thumbnailUrl\": \"Tujhse Naaraz Nahi Zindagi\", \"channelTitle\": \"Tujhse Naaraz Nahi Zindagi\"}, {\"videoId\": \"Jay-Jaykara\", \"title\": \"Jay-Jaykara\", \"thumbnailUrl\": \"Jay-Jaykara\", \"channelTitle\": \"Jay-Jaykara\"}, {\"videoId\": \"Yeh Kasoor Mera Hai\", \"title\": \"Yeh Kasoor Mera Hai\", \"thumbnailUrl\": \"Yeh Kasoor Mera Hai\", \"channelTitle\": \"Yeh Kasoor Mera Hai\"}]'"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "string = \"My life is messed up\"\n",
        "songs = rec(string)\n",
        "print(f'Statement:',string)\n",
        "songs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JFa-MY0QhKuS"
      },
      "outputs": [],
      "source": [
        "# from sklearn.pipeline import Pipeline\n",
        "# from sklearn.svm import SVC\n",
        "# from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# pipe_svm = Pipeline(steps=[('cv', CountVectorizer()), ('svm', SVC())])\n",
        "# pipe_svm.fit(x_train, y_train)\n",
        "\n",
        "# score = pipe_svm.score(x_test, y_test)\n",
        "# print(f'Accuracy score: {score:.4f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bviTtwQMmBEw"
      },
      "outputs": [],
      "source": [
        "# from sklearn.metrics import classification_report\n",
        "\n",
        "# y_pred = pipe_svm.predict(x_test)\n",
        "# report = classification_report(y_test, y_pred)\n",
        "# print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UFSIvX96ipHC"
      },
      "outputs": [],
      "source": [
        "# from sklearn.pipeline import Pipeline\n",
        "# from sklearn.ensemble import RandomForestClassifier\n",
        "# from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# pipe_rf = Pipeline(steps=[('cv', CountVectorizer()), ('rf', RandomForestClassifier())])\n",
        "# pipe_rf.fit(x_train, y_train)\n",
        "\n",
        "# score = pipe_rf.score(x_test, y_test)\n",
        "# print(f'Accuracy score: {score:.4f}') \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yGnKLw6fl4uy"
      },
      "outputs": [],
      "source": [
        "# from sklearn.metrics import classification_report\n",
        "\n",
        "# y_pred = pipe_rf.predict(x_test)\n",
        "# report = classification_report(y_test, y_pred)\n",
        "# print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHvXnZuk7i72",
        "outputId": "80111dbf-0c7a-4187-f955-30f2818875e0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<7043x25295 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 51496 stored elements in Compressed Sparse Row format>"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uto4pu4hdmFP"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "pickle_out = open('classifier.pkl',\"wb\")\n",
        "pickle.dump(lr,pickle_out)\n",
        "pickle_out.close()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}